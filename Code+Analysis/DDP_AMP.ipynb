{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e339b9e0-bd21-4aec-adb6-7108380b4384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: Tesla V100-SXM2-32GB (UUID: GPU-ca3aed3d-2f15-4bb6-90df-13b26ca00a91)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f46b30c5-a09e-481c-8de8-2d9b5ffb5e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Dec 10 18:12:28 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB           On  | 00000000:18:00.0 Off |                    0 |\n",
      "| N/A   39C    P0              42W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ebbfd93-77e5-4fc0-ae10-e79cb439def6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting single_gpu_ddp_amp_benchmark.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile single_gpu_ddp_amp_benchmark.py\n",
    "import os\n",
    "import time\n",
    "import socket\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# AMP Imports (Robust check for newer PyTorch versions)\n",
    "try:\n",
    "    from torch.amp import autocast, GradScaler\n",
    "    USE_NEW_AMP = True\n",
    "except ImportError:\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "    USE_NEW_AMP = False\n",
    "\n",
    "# ============================================================\n",
    "# 1. SETUP / CLEANUP\n",
    "# ============================================================\n",
    "\n",
    "def find_free_port():\n",
    "    \"\"\"Finds a random open port on the machine.\"\"\"\n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "        s.bind(('', 0))\n",
    "        return s.getsockname()[1]\n",
    "\n",
    "def setup_dist(rank, world_size, port):\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = str(port)\n",
    "    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n",
    "    torch.cuda.set_device(rank)\n",
    "\n",
    "def cleanup_dist():\n",
    "    dist.destroy_process_group()\n",
    "\n",
    "# ============================================================\n",
    "# 2. DATASET & MODEL\n",
    "# ============================================================\n",
    "\n",
    "class OralCancerDataset(Dataset):\n",
    "    def __init__(self, dataframe, path_map, transform=None):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.path_map = path_map\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        img_id = row['id']\n",
    "        label = int(row['label'])\n",
    "        \n",
    "        img_path = self.path_map.get(img_id)\n",
    "        if img_path is None:\n",
    "            image = Image.new('RGB', (96, 96))\n",
    "        else:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 12 * 12, 256)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = x.view(-1, 128 * 12 * 12)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# ============================================================\n",
    "# 3. TRAINING WORKER (DDP + AMP + RESUME)\n",
    "# ============================================================\n",
    "\n",
    "def train_worker(rank, world_size, df, path_map, batch_size, num_epochs, csv_path, port):\n",
    "    setup_dist(rank, world_size, port)\n",
    "    device = torch.device(f\"cuda:{rank}\")\n",
    "    \n",
    "    # --- Transforms ---\n",
    "    IMG_SIZE = 96\n",
    "    train_tf = transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5]*3, [0.5]*3),\n",
    "    ])\n",
    "    val_tf = transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5]*3, [0.5]*3),\n",
    "    ])\n",
    "\n",
    "    # --- Split ---\n",
    "    train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"label\"])\n",
    "    \n",
    "    train_dataset = OralCancerDataset(train_df, path_map, transform=train_tf)\n",
    "    val_dataset   = OralCancerDataset(val_df,   path_map, transform=val_tf)\n",
    "\n",
    "    # --- Samplers (Required for DDP) ---\n",
    "    train_sampler = DistributedSampler(train_dataset, num_replicas=world_size, rank=rank, shuffle=True)\n",
    "    val_sampler   = DistributedSampler(val_dataset, num_replicas=world_size, rank=rank, shuffle=False)\n",
    "\n",
    "    # --- Loaders ---\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, \n",
    "                              num_workers=0, pin_memory=True)\n",
    "    val_loader   = DataLoader(val_dataset, batch_size=batch_size, sampler=val_sampler, \n",
    "                              num_workers=0, pin_memory=True)\n",
    "\n",
    "    # --- Model Setup ---\n",
    "    model = SimpleCNN().to(device)\n",
    "    # Wrap model with DDP\n",
    "    model = DDP(model, device_ids=[rank])\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    # --- CHECKPOINT & RESUME LOGIC ---\n",
    "    ckpt_dir = \"checkpoints_ddp_amp_fresh\"\n",
    "    if rank == 0:\n",
    "        os.makedirs(ckpt_dir, exist_ok=True)\n",
    "    \n",
    "    # Ensure dir exists before others proceed\n",
    "    dist.barrier()\n",
    "    \n",
    "    ckpt_path = os.path.join(ckpt_dir, f\"1gpu_ddp_amp_batch{batch_size}.pt\")\n",
    "\n",
    "    start_epoch = 0\n",
    "    if os.path.exists(ckpt_path):\n",
    "        if rank == 0:\n",
    "            print(f\"[RESUME] Found checkpoint for Batch {batch_size}. Loading...\")\n",
    "        \n",
    "        # Load to specific device\n",
    "        map_location = f\"cuda:{rank}\"\n",
    "        checkpoint = torch.load(ckpt_path, map_location=map_location)\n",
    "        \n",
    "        model.module.load_state_dict(checkpoint['model_state'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state'])\n",
    "        scaler.load_state_dict(checkpoint['scaler_state'])\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        \n",
    "        if rank == 0:\n",
    "            print(f\"[RESUME] Resuming from Epoch {start_epoch}\")\n",
    "    else:\n",
    "        if rank == 0:\n",
    "            print(f\"[START] No checkpoint found. Starting fresh for Batch {batch_size}\")\n",
    "\n",
    "    if start_epoch >= num_epochs:\n",
    "        if rank == 0:\n",
    "            print(f\"Batch {batch_size} already completed {start_epoch} epochs. Skipping.\")\n",
    "        cleanup_dist()\n",
    "        return\n",
    "\n",
    "    # --- TRAINING LOOP ---\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        train_sampler.set_epoch(epoch)\n",
    "        torch.cuda.reset_peak_memory_stats(device)\n",
    "        epoch_start = time.time()\n",
    "\n",
    "        # 1. Train\n",
    "        model.train()\n",
    "        train_loss_sum = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = labels.float().unsqueeze(1).to(device, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # AMP Context\n",
    "            if USE_NEW_AMP:\n",
    "                amp_ctx = autocast(device_type=\"cuda\")\n",
    "            else:\n",
    "                amp_ctx = autocast()\n",
    "                \n",
    "            with amp_ctx:\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Scaled Backward\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_loss_sum += loss.item() * images.size(0)\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            preds = (probs >= 0.5).float()\n",
    "            train_correct += (preds == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "\n",
    "        epoch_time = time.time() - epoch_start\n",
    "\n",
    "        # 2. Validation\n",
    "        model.eval()\n",
    "        val_loss_sum = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device, non_blocking=True)\n",
    "                labels = labels.float().unsqueeze(1).to(device, non_blocking=True)\n",
    "                \n",
    "                if USE_NEW_AMP:\n",
    "                    amp_ctx = autocast(device_type=\"cuda\")\n",
    "                else:\n",
    "                    amp_ctx = autocast()\n",
    "                \n",
    "                with amp_ctx:\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss_sum += loss.item() * images.size(0)\n",
    "                probs = torch.sigmoid(outputs)\n",
    "                preds = (probs >= 0.5).float()\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        # 3. Aggregation (Reduced across ranks)\n",
    "        metrics_tensor = torch.tensor([\n",
    "            train_loss_sum, train_correct, train_total,\n",
    "            val_loss_sum, val_correct, val_total\n",
    "        ], device=device)\n",
    "        \n",
    "        dist.all_reduce(metrics_tensor, op=dist.ReduceOp.SUM)\n",
    "        \n",
    "        # Unpack\n",
    "        g_train_loss = metrics_tensor[0].item() / metrics_tensor[2].item()\n",
    "        g_train_acc  = metrics_tensor[1].item() / metrics_tensor[2].item()\n",
    "        g_val_loss   = metrics_tensor[3].item() / metrics_tensor[5].item()\n",
    "        g_val_acc    = metrics_tensor[4].item() / metrics_tensor[5].item()\n",
    "\n",
    "        peak_mem = torch.cuda.max_memory_allocated(device)\n",
    "        peak_mem_gb = peak_mem / (1024**3)\n",
    "\n",
    "        if rank == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} | Batch {batch_size} | \"\n",
    "                  f\"TrainAcc={g_train_acc:.4f} ValAcc={g_val_acc:.4f} | \"\n",
    "                  f\"Time={epoch_time:.2f}s Mem={peak_mem_gb:.2f}GB\")\n",
    "\n",
    "            # Save Checkpoint (Stores NEXT epoch index to resume from)\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state': model.module.state_dict(),\n",
    "                'optimizer_state': optimizer.state_dict(),\n",
    "                'scaler_state': scaler.state_dict()\n",
    "            }, ckpt_path)\n",
    "\n",
    "            # Log to CSV\n",
    "            row = {\n",
    "                \"mode\": \"ddp_amp\",\n",
    "                \"gpu_count\": world_size, # Should be 1\n",
    "                \"batch_size\": batch_size,\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"train_loss\": g_train_loss,\n",
    "                \"train_acc\": g_train_acc,\n",
    "                \"val_loss\": g_val_loss,\n",
    "                \"val_acc\": g_val_acc,\n",
    "                \"epoch_time\": epoch_time,\n",
    "                \"peak_mem_bytes\": peak_mem,\n",
    "                \"peak_mem_gb\": peak_mem_gb\n",
    "            }\n",
    "            \n",
    "            file_exists = os.path.exists(csv_path)\n",
    "            pd.DataFrame([row]).to_csv(csv_path, mode=\"a\", header=not file_exists, index=False)\n",
    "\n",
    "    cleanup_dist()\n",
    "\n",
    "# ============================================================\n",
    "# 4. MAIN\n",
    "# ============================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mp.set_start_method(\"spawn\", force=True)\n",
    "    \n",
    "    CSV_FILE = \"DDP_AMP_metrics.csv\"\n",
    "    \n",
    "    # 1. Load Data\n",
    "    print(\"Loading Dataset...\")\n",
    "    df = pd.read_csv(\"oral_cancer_balanced.csv\")\n",
    "    \n",
    "    path_map = {}\n",
    "    for root, dirs, files in os.walk(\"Data\"):\n",
    "        if \"val\" in dirs: dirs.remove(\"val\")\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                path_map[file] = os.path.join(root, file)\n",
    "                \n",
    "    # 2. Configurations\n",
    "    BATCH_SIZES = [64, 128, 512]\n",
    "    NUM_EPOCHS = 10\n",
    "    GPU_COUNT = 1\n",
    "    \n",
    "    print(f\"Starting Single GPU DDP+AMP Benchmark. Saving to {CSV_FILE}\")\n",
    "    \n",
    "    for bs in BATCH_SIZES:\n",
    "        # Find a fresh port for each run to avoid \"Address already in use\"\n",
    "        port = find_free_port()\n",
    "        print(f\"\\n=== Starting Run: Batch Size {bs} (Port {port}) ===\")\n",
    "        \n",
    "        try:\n",
    "            mp.spawn(\n",
    "                train_worker,\n",
    "                args=(GPU_COUNT, df, path_map, bs, NUM_EPOCHS, CSV_FILE, port),\n",
    "                nprocs=GPU_COUNT,\n",
    "                join=True\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error running batch size {bs}: {e}\")\n",
    "            \n",
    "    print(f\"\\nAll runs completed. Check {CSV_FILE} for results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fe32db0-20ce-484c-9e72-b5e00734d0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dataset...\n",
      "Starting Single GPU DDP+AMP Benchmark. Saving to DDP_AMP_metrics.csv\n",
      "\n",
      "=== Starting Run: Batch Size 64 (Port 34255) ===\n",
      "[RESUME] Found checkpoint for Batch 64. Loading...\n",
      "[RESUME] Resuming from Epoch 10\n",
      "Batch 64 already completed 10 epochs. Skipping.\n",
      "\n",
      "=== Starting Run: Batch Size 128 (Port 53961) ===\n",
      "[RESUME] Found checkpoint for Batch 128. Loading...\n",
      "[RESUME] Resuming from Epoch 8\n",
      "Epoch 9/10 | Batch 128 | TrainAcc=0.9248 ValAcc=0.9255 | Time=545.91s Mem=0.56GB\n",
      "Epoch 10/10 | Batch 128 | TrainAcc=0.9292 ValAcc=0.9173 | Time=251.51s Mem=0.56GB\n",
      "\n",
      "=== Starting Run: Batch Size 512 (Port 48881) ===\n",
      "[START] No checkpoint found. Starting fresh for Batch 512\n",
      "Epoch 1/10 | Batch 512 | TrainAcc=0.8054 ValAcc=0.8299 | Time=276.78s Mem=1.86GB\n",
      "Epoch 2/10 | Batch 512 | TrainAcc=0.8494 ValAcc=0.8638 | Time=296.92s Mem=1.86GB\n",
      "Epoch 3/10 | Batch 512 | TrainAcc=0.8625 ValAcc=0.8603 | Time=275.33s Mem=1.86GB\n",
      "Epoch 4/10 | Batch 512 | TrainAcc=0.8745 ValAcc=0.8825 | Time=264.62s Mem=1.86GB\n",
      "Epoch 5/10 | Batch 512 | TrainAcc=0.8835 ValAcc=0.8871 | Time=248.88s Mem=1.86GB\n",
      "Epoch 7/10 | Batch 512 | TrainAcc=0.8959 ValAcc=0.8810 | Time=243.37s Mem=1.86GB\n",
      "Epoch 8/10 | Batch 512 | TrainAcc=0.9000 ValAcc=0.8667 | Time=242.40s Mem=1.86GB\n",
      "Epoch 9/10 | Batch 512 | TrainAcc=0.9061 ValAcc=0.8925 | Time=244.58s Mem=1.86GB\n",
      "Epoch 10/10 | Batch 512 | TrainAcc=0.9093 ValAcc=0.8996 | Time=241.75s Mem=1.86GB\n",
      "\n",
      "All runs completed. Check DDP_AMP_metrics.csv for results.\n"
     ]
    }
   ],
   "source": [
    "!python single_gpu_ddp_amp_benchmark.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b5bcf7-8dad-4088-beb0-4c8150e892a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (hpc)",
   "language": "python",
   "name": "hpc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
